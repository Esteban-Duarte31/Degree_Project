{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformación dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import googlemaps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo shape\n",
    "shapefile_path = \"../shapes/shape_boyaca_municipios.shp\"\n",
    "\n",
    "# Carpeta que contiene los archivos .nc (Descargando usando el notebook 1.get_data.ipynb)\n",
    "nc_folder_path = \"../data/archivos_climate_serv/\"\n",
    "\n",
    "# Cargar el archivo shape\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Obtener las coordenadas extremas iniciales\n",
    "min_latitude = float('inf')\n",
    "max_latitude = float('-inf')\n",
    "min_longitude = float('inf')\n",
    "max_longitude = float('-inf')\n",
    "\n",
    "# Iterar sobre los polígonos del archivo shape\n",
    "for i, geometry in enumerate(gdf.geometry):\n",
    "    # Obtener los límites de latitud y longitud del polígono actual\n",
    "    polygon_bounds = geometry.bounds\n",
    "    \n",
    "    # Actualizar los valores máximos y mínimos de latitud y longitud\n",
    "    min_latitude = min(min_latitude, polygon_bounds[1])\n",
    "    max_latitude = max(max_latitude, polygon_bounds[3])\n",
    "    min_longitude = min(min_longitude, polygon_bounds[0])\n",
    "    max_longitude = max(max_longitude, polygon_bounds[2])\n",
    "\n",
    "min_longitude -= 0.001\n",
    "max_longitude += 0.001\n",
    "\n",
    "# Crear una lista para almacenar los datos filtrados\n",
    "filtered_datasets = []\n",
    "\n",
    "# Obtener la lista de archivos .nc en la carpeta\n",
    "nc_file_paths = glob.glob(nc_folder_path + \"*.nc\")\n",
    "\n",
    "# Iterar sobre los archivos .nc\n",
    "for nc_file_path in nc_file_paths:\n",
    "    # Leer el archivo .nc utilizando xarray\n",
    "    ds = xr.open_dataset(nc_file_path)\n",
    "    \n",
    "    # Filtrar por latitud y longitud máximas y mínimas\n",
    "    ds_filtered = ds.sel(\n",
    "        longitude=slice(min_longitude, max_longitude),\n",
    "        latitude=slice(min_latitude, max_latitude)\n",
    "    )\n",
    "    \n",
    "    # Agregar el dataset filtrado a la lista\n",
    "    filtered_datasets.append(ds_filtered)\n",
    "\n",
    "# Combinar los datasets filtrados en uno solo\n",
    "combined_dataset = xr.concat(filtered_datasets, dim=\"time\")\n",
    "\n",
    "# Ruta para guardar el archivo .nc combinado\n",
    "output_nc_path = \"../data/data_filtered.nc\"\n",
    "\n",
    "# Guardar el dataset combinado en un nuevo archivo .nc\n",
    "combined_dataset.to_netcdf(output_nc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo .nc utilizando xarray\n",
    "data_filtered = xr.open_dataset('../data/data_filtered.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe a partir del archivo .nc\n",
    "df_filtered = data_filtered.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los pares de latitud y longitud únicos\n",
    "lat_lon = df_filtered[['latitude', 'longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una instancia del cliente de Google Maps\n",
    "gmaps = googlemaps.Client(key='API_KEY')\n",
    "\n",
    "# Define una función para obtener el municipio y departamento a partir de las coordenadas\n",
    "def get_municipality_department(lat, lng):\n",
    "    # Realiza la geocodificación inversa\n",
    "    reverse_geocode_result = gmaps.reverse_geocode((lat, lng))\n",
    "    \n",
    "    # Busca el municipio y departamento en los resultados\n",
    "    municipality = None\n",
    "    department = None\n",
    "    for result in reverse_geocode_result:\n",
    "        for component in result['address_components']:\n",
    "            if 'administrative_area_level_2' in component['types']:\n",
    "                municipality = component['long_name']\n",
    "            elif 'administrative_area_level_1' in component['types']:\n",
    "                department = component['long_name']\n",
    "    \n",
    "    return municipality, department\n",
    "\n",
    "# Obtener los pares de latitud y longitud únicos\n",
    "lat_lon_unique = lat_lon.drop_duplicates()\n",
    "\n",
    "# Crea listas vacías para almacenar los municipios y departamentos\n",
    "municipalities = []\n",
    "departments = []\n",
    "\n",
    "# Itera sobre los pares de latitud y longitud únicos y obtiene el municipio y departamento correspondientes\n",
    "for index, row in lat_lon_unique.iterrows():\n",
    "    lat = row['latitude']\n",
    "    lon = row['longitude']\n",
    "    municipality, department = get_municipality_department(lat, lon)\n",
    "    municipalities.append(municipality)\n",
    "    departments.append(department)\n",
    "\n",
    "# Agrega las columnas de municipio y departamento al DataFrame\n",
    "lat_lon_unique['municipality'] = municipalities\n",
    "lat_lon_unique['department'] = departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer un merge entre el DataFrame original y el DataFrame con los municipios y departamentos\n",
    "df_filtered_merge = df_filtered.merge(lat_lon_unique, on=['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por departamento Boyacá\n",
    "df_boyaca = df_filtered_merge[df_filtered_merge['department'] == 'Boyaca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df_boyaca = df_boyaca.reset_index(drop=True)\n",
    "# Eliminar columna de departamento\n",
    "df_boyaca = df_boyaca.drop(columns=['department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo .nc\n",
    "ds_boyaca = df_boyaca.to_xarray()\n",
    "ds_boyaca.to_netcdf('../data/data_boyaca_final.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
